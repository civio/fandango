---
title: Publications
date: 2018-02-28 12:40:00 Z
permalink: "/achievements/publications/"
position: 2
navigation_order: 3
navigation_parent: Achievements
---

#### Overview

{: .resources-list}

* F. Nucci, M. Magaldi, L. Bevilacqua, "[FANDANGO (FAke News discovery and propagation from big Data and artificial inteliGence Operations) un approccio centrato sulla AI per contrastare la disinformazione](http://www.ital-ia.it/workshop/ai-for-media-and-entertainment)", [Ital-IA](http://www.ital-ia.it), March 2019.

  > FANDANGO è un importante progetto di ricerca industriale della durata di 36 mesi, cofinanziato dalla UE. FANDANGO vuole realizzare, nell’ambito di una piattaforma orientata all’analisi dei Big Data, un insieme di strumenti di AI capaci di coadiuvare l’identificazione di notizie false o fuorvianti sulla base di indizi derivanti dall’analisi della struttura testuale della notizia, dei media ad essa associati e - ove possibile - del riscontro con fonti dati aperte e affidabili.
  > I risultati di FANDANGO sono rivolti all’uso da parte di professionisti del settore (giornalisti) che pur non volendo delegare completamente il proprio giudizio circa la veridicità e affidabilità di una specifica notizia a sistemi totalmente automatici, sentono l’esigenza di sistemi di supporto che forniscano specifiche valutazioni circa potenziali indizi di manipolazione.

#### Machine Learning

{: .resources-list}
* G. Palaiopanos, P. Stalidis, T. Semertzidis, N. Vretos, P. Daras, "[Embedding Big Data in Graph Convolutional Networks](https://doi.org/10.1109/ICE.2019.8792632)", [25th International Conference on Engineering, Technology and Innovation](http://www.ice-conference.org/) (ICE/IEEE ITMC 2019), Sophia Antipolis Innovation Park, France, 17-19 June 2019.

  > Deep learning architectures and Convolutional Neural Networks (CNNs) have made a significant impact in learning embeddings of high-dimensional datasets. In some cases, and especially in the case of high-dimensional graph data, the interlinkage of data points may be hard to model. Previous approaches in applying the convolution function on graphs, namely the Graph Convolutional Networks (GCNs), presented neural networks architectures that encode information of individual nodes along with their connectivity. Nonetheless, these methods face the same issues as in traditional graph-based machine learning techniques i.e. the requirement of full matrix computations. This requirement bounds the applicability of the GCNs on the available computational resources. In this paper, the following assumption is evaluated: the training of a GCN with multiple subsets of the full data matrix is possible and converges to the full data matrix training scores, thus lifting the aforementioned limitation. Following this outcome, different subset selection methodologies are also examined to evaluate the impact of the learning curriculum in the performance of the trained model in small as well as very large scale graph datasets.

* M. Angelou, V. Solachidis, N. Vretos, P. Daras, "[Graph-based Multimodal Fusion with metric learning for multimodal classification](https://doi.org/10.1016/j.patcog.2019.06.013)", Pattern Recognition, Elsevier, Volume 95, Pages 296-307, November 2019

  > In this paper, a graph-based, supervised classification method for multimodal data is introduced. It can be applied on data of any type consisting of any number of modalities and can also be used for the classification of datasets with missing modalities. The proposed method maps the features extracted from every modality to a space where the intrinsic structure of the multimodal data is kept. In order to map the extracted features of the different modalities into the same space and, at the same time, maintain the feature distances between similar and dissimilar modality data instances, a metric learning method is used. The proposed method has been evaluated on NUS-Wide, NTU-RGBD and AV-Letters multimodal datasets and has shown competitive results with the state-of-the-art methods in the field, while is able to cope with datasets with missing modalities.

* D. Martín-Gutiérrez, G. Hernández-Peñaloza, J.M. Menéndez, F. Álvarez, "[A Multi-Modal approach for FAke News discovery and propagation from big Data ANalysis and artificial inteliGence Operations](https://nem-initiative.org/wp-content/uploads/2020/07/1-5-a_multimodal_approach_for_fake_news_discovery_and_propagation.pdf)", NEM Summit 2020, Research Article, June 2020.

  > The analysis of data collected from diverse sources such as news, claims, open data and media can provide valuable insights for early detection and propagation traceability of events related to fake news. This article describes a novel system that involves data ingestion, processing and analysis to extract relevant features and serve as a means of verification of multimedia contents. The modular ecosystem treats the information from a modality perspective (i.e. text, images, videos, meta-data) and offers both single and global evaluation of the content’s trustworthiness probability. The system is being implemented and tested in relevant topic scenarios including migration, climate change and Europe.
