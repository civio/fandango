---
title: Publications
date: 2018-02-28 12:40:00 Z
permalink: "/achievements/publications/"
position: 0
navigation_order: 1
navigation_parent: Achievements
---

#### AI

{: .resources-list}
* Martín-Gutiérez, D; Hernández Peñazola, G; Belmonte-Hernández, A; Lozano-Díez, A; Álvarez. F. **[A Deep Learning Approach for Robust Detection of Bots in Twitter using Transformers](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9385071)**. IEEE Access. Page(s): 1-11. Print ISSN: 2169-3536. Online ISSN: 2169-3536. Identifier: 10.1109/ACCESS.2021.3068659

  > During the last decades, the volume of multimedia content posted in social networks has grown exponentially and such information is immediately propagated and consumed by a significant number of users. In this scenario, the disruption of fake news providers and bot accounts for spreading propaganda information as well as sensitive content throughout the network has fostered applied research to automatically measure the reliability of social networks accounts via Artificial Intelligence (AI). In this
paper, we present a multilingual approach for addressing the bot identification task in Twitter via Deep learning (DL) approaches to support end-users when checking the credibility of a certain Twitter account. To do so, several experiments were conducted using state-of-the-art Multilingual Language Models to generate an encoding of the text-based features of the user account that are later on concatenated with the rest of the metadata to build a potential input vector on top of a Dense Network denoted as Bot-DenseNet. Consequently, this paper assesses the language constraint from previous studies where the encoding of the user account only considered either the metadata information or the metadata information together with some basic semantic text features. Moreover, the Bot-DenseNet produces a low-dimensional representation of the user account which can be used for any application within the Information Retrieval (IR) framework.

{: .resources-list}
* Chatzitofis, A.; Cancian, P.; Gkitsas, V.; Carlucci, A.; Stalidis, P.; Albanis, G.; Karakottas, A.; Semertzidis, T.; Daras, P.; Giannitto, C.; Casiraghi, E.; Sposta, F.M.; Vatteroni, G.; Ammirabile, A.; Lofino, L.; Ragucci, P.; Laino, M.E.; Voza, A.; Desai, A.; Cecconi, M.; Balzarini, L.; Chiti, A.; Zarpalas, D.; Savevski, V. **[Volume-of-Interest Aware Deep Neural Networks for Rapid Chest CT-Based COVID-19 Patient Risk Assessment](https://www.mdpi.com/1660-4601/18/6/2842/htm)**. Int. J. Environ. Res. Public Health 2021, 18, 2842. https://doi.org/10.3390/ijerph18062842

  > Since December 2019, the world has been devastated by the Coronavirus Disease 2019 (COVID-19) pandemic. Emergency Departments have been experiencing situations of urgency where clinical experts, without long experience and mature means in the fight against COVID-19, have to rapidly decide the most proper patient treatment. In this context, we introduce an artificially intelligent tool for effective and efficient Computed Tomography (CT)-based risk assessment to improve treatment and patient care. In this paper, we introduce a data-driven approach built on top of volume-of-interest aware deep neural networks for automatic COVID-19 patient risk assessment (discharged, hospitalized, intensive care unit) based on lung infection quantization through segmentation and, subsequently, CT classification. We tackle the high and varying dimensionality of the CT input by detecting and analyzing only a sub-volume of the CT, the Volume-of-Interest (VoI). Differently from recent strategies that consider infected CT slices without requiring any spatial coherency between them, or use the whole lung volume by applying abrupt and lossy volume down-sampling, we assess only the “most infected volume” composed of slices at its original spatial resolution. To achieve the above, we create, present and publish a new labeled and annotated CT dataset with 626 CT samples from COVID-19 patients. The comparison against such strategies proves the effectiveness of our VoI-based approach. We achieve remarkable performance on patient risk assessment evaluated on balanced data by reaching 88.88%, 89.77%, 94.73% and 88.88% accuracy, sensitivity, specificity and F1-score, respectively.

#### Machine Learning

{: .resources-list}
* G. Palaiopanos, P. Stalidis, T. Semertzidis, N. Vretos, P. Daras, "[Embedding Big Data in Graph Convolutional Networks](https://doi.org/10.1109/ICE.2019.8792632)", [25th International Conference on Engineering, Technology and Innovation](http://www.ice-conference.org/) (ICE/IEEE ITMC 2019), Sophia Antipolis Innovation Park, France, 17-19 June 2019.

  > Deep learning architectures and Convolutional Neural Networks (CNNs) have made a significant impact in learning embeddings of high-dimensional datasets. In some cases, and especially in the case of high-dimensional graph data, the interlinkage of data points may be hard to model. Previous approaches in applying the convolution function on graphs, namely the Graph Convolutional Networks (GCNs), presented neural networks architectures that encode information of individual nodes along with their connectivity. Nonetheless, these methods face the same issues as in traditional graph-based machine learning techniques i.e. the requirement of full matrix computations. This requirement bounds the applicability of the GCNs on the available computational resources. In this paper, the following assumption is evaluated: the training of a GCN with multiple subsets of the full data matrix is possible and converges to the full data matrix training scores, thus lifting the aforementioned limitation. Following this outcome, different subset selection methodologies are also examined to evaluate the impact of the learning curriculum in the performance of the trained model in small as well as very large scale graph datasets.

* M. Angelou, V. Solachidis, N. Vretos, P. Daras, "[Graph-based Multimodal Fusion with metric learning for multimodal classification](https://doi.org/10.1016/j.patcog.2019.06.013)", Pattern Recognition, Elsevier, Volume 95, Pages 296-307, November 2019

  > In this paper, a graph-based, supervised classification method for multimodal data is introduced. It can be applied on data of any type consisting of any number of modalities and can also be used for the classification of datasets with missing modalities. The proposed method maps the features extracted from every modality to a space where the intrinsic structure of the multimodal data is kept. In order to map the extracted features of the different modalities into the same space and, at the same time, maintain the feature distances between similar and dissimilar modality data instances, a metric learning method is used. The proposed method has been evaluated on NUS-Wide, NTU-RGBD and AV-Letters multimodal datasets and has shown competitive results with the state-of-the-art methods in the field, while is able to cope with datasets with missing modalities.

* D. Martín-Gutiérrez, G. Hernández-Peñaloza, J.M. Menéndez, F. Álvarez, "[A Multi-Modal approach for FAke News discovery and propagation from big Data ANalysis and artificial inteliGence Operations](https://nem-initiative.org/wp-content/uploads/2020/07/1-5-a_multimodal_approach_for_fake_news_discovery_and_propagation.pdf)", NEM Summit 2020, Research Article, June 2020.

  > The analysis of data collected from diverse sources such as news, claims, open data and media can provide valuable insights for early detection and propagation traceability of events related to fake news. This article describes a novel system that involves data ingestion, processing and analysis to extract relevant features and serve as a means of verification of multimedia contents. The modular ecosystem treats the information from a modality perspective (i.e. text, images, videos, meta-data) and offers both single and global evaluation of the content’s trustworthiness probability. The system is being implemented and tested in relevant topic scenarios including migration, climate change and Europe.

#### Overview

{: .resources-list}

* F. Nucci, S. Boi, M. Magaldi, [Artificial Intelligence against disinformation: the FANDANGO practical case](http://ceur-ws.org/Vol-2781/paper3.pdf). [IFDaD 2020](http://ceur-ws.org/Vol-2781/), December 2020.

 > The present paper discusses how Artificial Intelligence can support the fight to disinformation to support a correct access to the news and content to the citizens, allowing the right democratic participation. The paper presents some results of a running EU co-funded project, named FANDANGO, describing its technological approach and architecture. In the first and second chapters the context of disinformation is presented, in chapter 3 and 4 the FANDANGO project is shortly described, including its AI approach and dataflow architecture, chapter 5 describes the project use cases: climate change, immigration, and European policies. Finally, some short conclusions conclude the paper with general considerations on the status of digital media and with some preliminary suggestions to enforce the media in European ecosystem. 

{: .resources-list}

* F. Nucci, M. Magaldi, L. Bevilacqua, "[FANDANGO (FAke News discovery and propagation from big Data and artificial inteliGence Operations) un approccio centrato sulla AI per contrastare la disinformazione](http://www.ital-ia.it/workshop/ai-for-media-and-entertainment)", [Ital-IA](http://www.ital-ia.it), March 2019.

  > FANDANGO è un importante progetto di ricerca industriale della durata di 36 mesi, cofinanziato dalla UE. FANDANGO vuole realizzare, nell’ambito di una piattaforma orientata all’analisi dei Big Data, un insieme di strumenti di AI capaci di coadiuvare l’identificazione di notizie false o fuorvianti sulla base di indizi derivanti dall’analisi della struttura testuale della notizia, dei media ad essa associati e - ove possibile - del riscontro con fonti dati aperte e affidabili.

  > I risultati di FANDANGO sono rivolti all’uso da parte di professionisti del settore (giornalisti) che pur non volendo delegare completamente il proprio giudizio circa la veridicità e affidabilità di una specifica notizia a sistemi totalmente automatici, sentono l’esigenza di sistemi di supporto che forniscano specifiche valutazioni circa potenziali indizi di manipolazione.